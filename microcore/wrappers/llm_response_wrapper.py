from typing import Any
from typing import TYPE_CHECKING

from ..images import FileImage, ImageInterface, ImageListInterface
from ..types import BadAIAnswer, TPrompt
from ..utils import (
    ExtendedString,
    ConvertableToMessage,
    extract_number,
    file_link,
)
from ..message_types import Role, AssistantMsg

if TYPE_CHECKING:
    from ..mcp import MCPConnection, MCPAnswer


class DictFromLLMResponse(dict):
    llm_response: "LLMResponse"

    def from_llm_response(self, llm_response: "LLMResponse"):
        self.llm_response = llm_response
        return self

    async def to_mcp(self, mcp: "MCPConnection"):
        return await mcp.exec(self)


class LLMResponse(ExtendedString, ConvertableToMessage):
    """
    Response from the Large Language Model.

    If treated as a string, it returns the text generated by the LLM.

    Also, it contains all fields returned by the API accessible as an attributes.

    See fields returned by the OpenAI:

    - https://platform.openai.com/docs/api-reference/completions/object
    - https://platform.openai.com/docs/api-reference/chat/object
    """

    role: Role
    content: str
    prompt: TPrompt
    gen_duration: float
    from_file_cache: bool = False

    def __new__(cls, string: str, attrs: dict = None, **kwargs):
        attrs = {
            "role": Role.ASSISTANT,
            "content": str(string),
            "prompt": None,
            # generation duration in seconds (float), used in metrics
            "gen_duration": None,
            **(attrs or {}),
        }
        obj = ExtendedString.__new__(cls, string, attrs, **kwargs)
        return obj

    def parse_json(
        self,
        raise_errors: bool = True,
        required_fields: list[str] = None,
        validator: callable = None,
    ) -> list | dict | float | int | str | DictFromLLMResponse:
        try:
            res = super().parse_json(raise_errors=True, required_fields=required_fields)
            if validator:
                try:
                    validator(res)
                except Exception as e:
                    raise BadAIAnswer(f"Language model response validation failed: {e}") from None
        except Exception as e:  # pylint: disable=W0718
            if hasattr(self, "_retry_callback"):
                res = self._retry_callback()
                if isinstance(res, DictFromLLMResponse):
                    return res
                return res.parse_json(raise_errors, required_fields, validator)
            if raise_errors:
                raise e
            res = False
        if isinstance(res, dict):
            res = DictFromLLMResponse(res)
            res.llm_response = self
        return res

    def parse_number(
        self,
        default=BadAIAnswer,
        position="last",
        dtype: type | str = float,
        rounding: bool = False,
    ) -> int | float | Any:
        return extract_number(self.content, default, position, dtype, rounding)

    def as_message(self) -> AssistantMsg:
        return self.as_assistant

    async def to_mcp(self, mcp: "MCPConnection") -> "MCPAnswer":
        return await mcp.exec(self)

    def is_tool_call(self):
        from ..ai_func import extract_tool_params
        return bool(extract_tool_params(self))

    def as_tool_call(
        self,
        toolset=None,
    ) -> tuple[str, list, dict] | None:
        """
        Extracts tool call from the LLM response.
        Args:
            toolset: Optional ToolSet to use for extraction.
            If not provided, uses default extractor.
        """
        from ..ai_func import extract_tool_params, ToolSet
        if isinstance(toolset, ToolSet):
            return toolset.extract_tool_params(self)
        return extract_tool_params(self)


# pylint: disable=too-many-ancestors
class ImageGenerationResponse(LLMResponse, ImageListInterface, ImageInterface):  #

    _images: list[ImageInterface]

    def images(self) -> list[ImageInterface]:
        return self._images

    def image(self):
        return self._images[0] if self._images else None

    def mime_type(self) -> str | None:
        return self.image().mime_type() if self.image() else None

    def get_bytes(self) -> bytes | None:
        return self.image().get_bytes() if self.image() else None

    def __new__(cls, str_repr: str = "<images>", images: list[ImageInterface] = None, **kwargs):
        images = images or []
        obj = LLMResponse.__new__(cls, str_repr, _images=images, **kwargs)
        return obj

    def display(self, **kwargs):
        for i in self.images():
            i.display(**kwargs)
        return self


class StoredImageGenerationResponse(ImageGenerationResponse):

    _images: list[FileImage]

    def __new__(cls, str_repr: str = "<images>", images: list[FileImage] = None, **kwargs):
        images = images or []
        if len(images) == 1:
            str_repr = file_link(images[0].file)
        elif len(images) > 1:
            str_repr = "\n".join(
                file_link(i.file) for i in images
            )
        obj = ImageGenerationResponse.__new__(
            cls,
            images=images,
            str_repr=str_repr,
            **kwargs
        )
        return obj

    @property
    def file(self) -> str | None:
        return self._images[0].file if self._images else None

    @property
    def files(self) -> list[str]:
        return [img.file for img in self._images]
